# SRP Meeting notes Saturday, 10.02.2024

## Members present:
Alex, Abin, Apurv, Steve

## Meeting Content

* In this meeting we synced up for the meeting with Diego the next day
* Alex gave a general introduction to Knowledge Destillation, based on a survery paper (https://drive.google.com/drive/folders/1bso4pnfPDpKvuoTfXzIfzJ5eJgeiyTc5)
* Although we don't have much time at the moment because of exams, we thought about some general Ideas we could present Diego
    * Use attention networks and transfer the attention maps from teacher to student
    * Use multiple projectors at intermediate layers to sync up the teacher and student features earlier and not only at the last layer
    * Try different losses for the feature allignment (Baseline only uses l2)
* Things we could also change but probably want to keep the same as the baseline paper
    * Offline learning (pre-trained teacher model)
        * We probably wouldn't even have the compute power to train a teacher model from scratch
    * Feature Based knowledge destillation
    * Using the teacher classifier for the student model

## Administration
* Alex can't acces the cluster, the link from Diego doesn't work
    * (Also didn't work on Steves laptop)