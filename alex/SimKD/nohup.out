Running: python train_student.py --path_t ./save/teachers/models/resnet38x2_vanilla_cifar100_trial_1/resnet38x2_best.pth --epochs 240 --learning_rate 0.01 --distill kd --model_s resnet8x4 -c 1 -d 1 -b 0 --trial 0 --gpu_id 0
Traceback (most recent call last):
  File "train_student.py", line 13, in <module>
    import torch
ModuleNotFoundError: No module named 'torch'
Command failed
Running: python train_student.py --path_t ./save/teachers/models/resnet38x2_vanilla_cifar100_trial_1/resnet38x2_best.pth --epochs 240 --learning_rate 0.01 --distill kd --model_s resnet8x4 -c 1 -d 1 -b 0 --trial 0 --gpu_id 0
2024-05-15 08:44:18.287263: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-15 08:44:19.038673: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Use GPU: 0 for training
==> loading teacher model
==> done
Files already downloaded and verified
Files already downloaded and verified
/home/wut/.conda/envs/sim-kd/lib/python3.10/site-packages/_distutils_hack/__init__.py:26: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")
Test: [0/313]	GPU: 0	Time: 0.190	Loss 0.9604	Acc@1 81.250	Acc@5 87.500
Test: [200/313]	GPU: 0	Time: 1.090	Loss 1.0121	Acc@1 76.150	Acc@5 93.532
teacher accuracy:  76.3
==> training...
Epoch: [1][0/782]	GPU 0	Time: 0.475	Loss 19.8076	Acc@1 0.000	Acc@5 4.688
Epoch: [1][200/782]	GPU 0	Time: 3.936	Loss 16.3565	Acc@1 5.924	Acc@5 21.144
Epoch: [1][400/782]	GPU 0	Time: 7.224	Loss 15.7935	Acc@1 7.855	Acc@5 26.543
Epoch: [1][600/782]	GPU 0	Time: 10.520	Loss 15.3483	Acc@1 9.658	Acc@5 30.447
 * Epoch 1, GPU 0, Acc@1 11.068, Acc@5 33.370, Time 26.60
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.188	Loss 4.2107	Acc@1 12.500	Acc@5 28.125
Test: [200/313]	GPU: 0	Time: 0.663	Loss 3.6363	Acc@1 17.055	Acc@5 44.061
 ** Acc@1 16.690, Acc@5 44.230
saving the best model!
==> training...
Epoch: [2][0/782]	GPU 0	Time: 0.285	Loss 12.4613	Acc@1 14.062	Acc@5 46.875
Epoch: [2][200/782]	GPU 0	Time: 3.669	Loss 13.3239	Acc@1 19.488	Acc@5 48.640
Epoch: [2][400/782]	GPU 0	Time: 7.009	Loss 13.0256	Acc@1 20.698	Acc@5 50.616
Epoch: [2][600/782]	GPU 0	Time: 10.356	Loss 12.8062	Acc@1 21.740	Acc@5 52.298
 * Epoch 2, GPU 0, Acc@1 22.890, Acc@5 53.908, Time 26.53
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.127	Loss 3.0231	Acc@1 34.375	Acc@5 59.375
Test: [200/313]	GPU: 0	Time: 0.582	Loss 3.2550	Acc@1 24.238	Acc@5 57.121
 ** Acc@1 24.590, Acc@5 57.130
saving the best model!
==> training...
Epoch: [3][0/782]	GPU 0	Time: 0.269	Loss 12.6120	Acc@1 29.688	Acc@5 56.250
Epoch: [3][200/782]	GPU 0	Time: 3.725	Loss 11.4787	Acc@1 29.322	Acc@5 61.831
Epoch: [3][400/782]	GPU 0	Time: 7.117	Loss 11.2689	Acc@1 30.276	Acc@5 62.964
Epoch: [3][600/782]	GPU 0	Time: 10.503	Loss 11.0909	Acc@1 30.998	Acc@5 63.909
 * Epoch 3, GPU 0, Acc@1 31.878, Acc@5 64.914, Time 26.81
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.123	Loss 2.6468	Acc@1 37.500	Acc@5 71.875
Test: [200/313]	GPU: 0	Time: 0.568	Loss 2.7723	Acc@1 33.598	Acc@5 66.713
 ** Acc@1 33.240, Acc@5 66.440
saving the best model!
==> training...
Epoch: [4][0/782]	GPU 0	Time: 0.276	Loss 9.8601	Acc@1 39.062	Acc@5 68.750
Epoch: [4][200/782]	GPU 0	Time: 3.707	Loss 10.0019	Acc@1 36.497	Acc@5 71.253
Epoch: [4][400/782]	GPU 0	Time: 7.097	Loss 9.8629	Acc@1 37.687	Acc@5 71.606
Epoch: [4][600/782]	GPU 0	Time: 10.497	Loss 9.7649	Acc@1 38.340	Acc@5 72.054
 * Epoch 4, GPU 0, Acc@1 39.234, Acc@5 72.640, Time 26.95
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.127	Loss 2.4411	Acc@1 46.875	Acc@5 71.875
Test: [200/313]	GPU: 0	Time: 0.581	Loss 2.6021	Acc@1 39.117	Acc@5 72.124
 ** Acc@1 38.970, Acc@5 71.800
saving the best model!
==> training...
Epoch: [5][0/782]	GPU 0	Time: 0.274	Loss 9.6495	Acc@1 32.812	Acc@5 73.438
Epoch: [5][200/782]	GPU 0	Time: 3.717	Loss 9.1014	Acc@1 42.910	Acc@5 75.653
Epoch: [5][400/782]	GPU 0	Time: 7.123	Loss 8.9509	Acc@1 43.594	Acc@5 76.348
Epoch: [5][600/782]	GPU 0	Time: 10.535	Loss 8.8632	Acc@1 44.304	Acc@5 76.859
 * Epoch 5, GPU 0, Acc@1 44.886, Acc@5 77.368, Time 27.01
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.124	Loss 2.2014	Acc@1 56.250	Acc@5 81.250
Test: [200/313]	GPU: 0	Time: 0.576	Loss 2.4396	Acc@1 43.268	Acc@5 75.840
 ** Acc@1 42.950, Acc@5 75.700
saving the best model!
==> training...
Epoch: [6][0/782]	GPU 0	Time: 0.271	Loss 7.7312	Acc@1 59.375	Acc@5 82.812
Epoch: [6][200/782]	GPU 0	Time: 3.735	Loss 8.2057	Acc@1 48.158	Acc@5 80.263
Epoch: [6][400/782]	GPU 0	Time: 7.137	Loss 8.1832	Acc@1 48.332	Acc@5 80.455
Epoch: [6][600/782]	GPU 0	Time: 10.544	Loss 8.1277	Acc@1 48.630	Acc@5 80.527
 * Epoch 6, GPU 0, Acc@1 49.064, Acc@5 80.750, Time 26.97
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.130	Loss 2.1650	Acc@1 62.500	Acc@5 78.125
Test: [200/313]	GPU: 0	Time: 0.575	Loss 2.0733	Acc@1 48.414	Acc@5 80.861
 ** Acc@1 48.480, Acc@5 80.550
saving the best model!
==> training...
Epoch: [7][0/782]	GPU 0	Time: 0.293	Loss 7.6738	Acc@1 45.312	Acc@5 85.938
Epoch: [7][200/782]	GPU 0	Time: 3.740	Loss 7.5724	Acc@1 51.594	Acc@5 82.797
Epoch: [7][400/782]	GPU 0	Time: 7.139	Loss 7.5604	Acc@1 51.738	Acc@5 82.832
Epoch: [7][600/782]	GPU 0	Time: 10.544	Loss 7.4902	Acc@1 52.127	Acc@5 83.098
 * Epoch 7, GPU 0, Acc@1 52.418, Acc@5 83.148, Time 26.96
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.123	Loss 1.9598	Acc@1 56.250	Acc@5 78.125
Test: [200/313]	GPU: 0	Time: 0.576	Loss 2.1224	Acc@1 49.378	Acc@5 80.970
 ** Acc@1 49.700, Acc@5 81.090
saving the best model!
==> training...
Epoch: [8][0/782]	GPU 0	Time: 0.273	Loss 6.7049	Acc@1 62.500	Acc@5 84.375
Epoch: [8][200/782]	GPU 0	Time: 3.729	Loss 7.1082	Acc@1 54.998	Acc@5 85.036
Epoch: [8][400/782]	GPU 0	Time: 7.130	Loss 7.0803	Acc@1 54.878	Acc@5 85.256
Epoch: [8][600/782]	GPU 0	Time: 10.529	Loss 7.0541	Acc@1 55.207	Acc@5 85.241
 * Epoch 8, GPU 0, Acc@1 55.306, Acc@5 85.178, Time 26.92
GPU 0 validating
2024/05/15 08:49:03 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under mlflow-artifacts:/2/77b785ebc142440dad9756db7b3e5449/artifacts. Set logging level to DEBUG via `logging.getLogger("mlflow").setLevel(logging.DEBUG)` to see the full traceback.
Test: [0/313]	GPU: 0	Time: 0.118	Loss 2.0816	Acc@1 56.250	Acc@5 78.125
Test: [200/313]	GPU: 0	Time: 0.555	Loss 1.9321	Acc@1 52.441	Acc@5 82.929
 ** Acc@1 52.580, Acc@5 83.010
saving the best model!
==> training...
Epoch: [9][0/782]	GPU 0	Time: 0.277	Loss 7.1791	Acc@1 56.250	Acc@5 79.688
Epoch: [9][200/782]	GPU 0	Time: 3.725	Loss 6.6202	Acc@1 57.618	Acc@5 86.769
Epoch: [9][400/782]	GPU 0	Time: 7.108	Loss 6.5941	Acc@1 58.042	Acc@5 86.744
Epoch: [9][600/782]	GPU 0	Time: 10.494	Loss 6.6237	Acc@1 57.838	Acc@5 86.621
 * Epoch 9, GPU 0, Acc@1 57.800, Acc@5 86.728, Time 26.83
GPU 0 validating
2024/05/15 08:49:37 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under mlflow-artifacts:/2/77b785ebc142440dad9756db7b3e5449/artifacts. Set logging level to DEBUG via `logging.getLogger("mlflow").setLevel(logging.DEBUG)` to see the full traceback.
Test: [0/313]	GPU: 0	Time: 0.126	Loss 2.1350	Acc@1 59.375	Acc@5 81.250
Test: [200/313]	GPU: 0	Time: 0.589	Loss 1.8694	Acc@1 54.555	Acc@5 83.598
 ** Acc@1 54.660, Acc@5 83.530
saving the best model!
==> training...
Epoch: [10][0/782]	GPU 0	Time: 0.286	Loss 6.3349	Acc@1 62.500	Acc@5 92.188
Epoch: [10][200/782]	GPU 0	Time: 3.723	Loss 6.3768	Acc@1 59.429	Acc@5 87.710
Epoch: [10][400/782]	GPU 0	Time: 7.115	Loss 6.3332	Acc@1 59.804	Acc@5 87.769
Epoch: [10][600/782]	GPU 0	Time: 10.504	Loss 6.3044	Acc@1 59.960	Acc@5 87.747
 * Epoch 10, GPU 0, Acc@1 59.922, Acc@5 87.728, Time 26.83
GPU 0 validating
2024/05/15 08:50:10 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under mlflow-artifacts:/2/77b785ebc142440dad9756db7b3e5449/artifacts. Set logging level to DEBUG via `logging.getLogger("mlflow").setLevel(logging.DEBUG)` to see the full traceback.
Test: [0/313]	GPU: 0	Time: 0.128	Loss 1.8465	Acc@1 62.500	Acc@5 84.375
Test: [200/313]	GPU: 0	Time: 0.589	Loss 1.8442	Acc@1 55.519	Acc@5 84.017
 ** Acc@1 55.670, Acc@5 83.990
saving the best model!
==> training...
Epoch: [11][0/782]	GPU 0	Time: 0.265	Loss 6.3860	Acc@1 60.938	Acc@5 89.062
Epoch: [11][200/782]	GPU 0	Time: 3.687	Loss 6.0261	Acc@1 61.894	Acc@5 88.938
Epoch: [11][400/782]	GPU 0	Time: 7.066	Loss 6.0703	Acc@1 61.713	Acc@5 88.614
Epoch: [11][600/782]	GPU 0	Time: 10.444	Loss 6.0569	Acc@1 61.613	Acc@5 88.566
 * Epoch 11, GPU 0, Acc@1 61.670, Acc@5 88.672, Time 26.74
GPU 0 validating
2024/05/15 08:50:44 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under mlflow-artifacts:/2/77b785ebc142440dad9756db7b3e5449/artifacts. Set logging level to DEBUG via `logging.getLogger("mlflow").setLevel(logging.DEBUG)` to see the full traceback.
Test: [0/313]	GPU: 0	Time: 0.125	Loss 1.7101	Acc@1 62.500	Acc@5 87.500
Test: [200/313]	GPU: 0	Time: 0.590	Loss 1.8333	Acc@1 55.613	Acc@5 85.215
 ** Acc@1 56.070, Acc@5 84.780
saving the best model!
==> training...
Epoch: [12][0/782]	GPU 0	Time: 0.290	Loss 5.5994	Acc@1 57.812	Acc@5 90.625
Epoch: [12][200/782]	GPU 0	Time: 3.714	Loss 5.8059	Acc@1 63.215	Acc@5 89.521
Epoch: [12][400/782]	GPU 0	Time: 7.092	Loss 5.8102	Acc@1 63.381	Acc@5 89.589
Epoch: [12][600/782]	GPU 0	Time: 10.469	Loss 5.8238	Acc@1 63.231	Acc@5 89.525
 * Epoch 12, GPU 0, Acc@1 63.380, Acc@5 89.582, Time 26.77
GPU 0 validating
2024/05/15 08:51:17 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under mlflow-artifacts:/2/77b785ebc142440dad9756db7b3e5449/artifacts. Set logging level to DEBUG via `logging.getLogger("mlflow").setLevel(logging.DEBUG)` to see the full traceback.
Test: [0/313]	GPU: 0	Time: 0.127	Loss 1.5740	Acc@1 59.375	Acc@5 87.500
Test: [200/313]	GPU: 0	Time: 0.575	Loss 1.7285	Acc@1 57.525	Acc@5 86.178
 ** Acc@1 58.070, Acc@5 86.140
saving the best model!
==> training...
Epoch: [13][0/782]	GPU 0	Time: 0.277	Loss 5.4631	Acc@1 70.312	Acc@5 90.625
Epoch: [13][200/782]	GPU 0	Time: 3.704	Loss 5.5259	Acc@1 65.197	Acc@5 90.361
Epoch: [13][400/782]	GPU 0	Time: 7.084	Loss 5.5697	Acc@1 65.142	Acc@5 90.189
Epoch: [13][600/782]	GPU 0	Time: 10.461	Loss 5.5663	Acc@1 65.069	Acc@5 90.297
 * Epoch 13, GPU 0, Acc@1 64.904, Acc@5 90.178, Time 26.79
GPU 0 validating
2024/05/15 08:51:51 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under mlflow-artifacts:/2/77b785ebc142440dad9756db7b3e5449/artifacts. Set logging level to DEBUG via `logging.getLogger("mlflow").setLevel(logging.DEBUG)` to see the full traceback.
Test: [0/313]	GPU: 0	Time: 0.122	Loss 1.4566	Acc@1 65.625	Acc@5 84.375
Test: [200/313]	GPU: 0	Time: 0.563	Loss 1.6650	Acc@1 59.188	Acc@5 86.925
 ** Acc@1 59.280, Acc@5 86.810
saving the best model!
==> training...
Epoch: [14][0/782]	GPU 0	Time: 0.268	Loss 5.1176	Acc@1 67.188	Acc@5 95.312
Epoch: [14][200/782]	GPU 0	Time: 3.703	Loss 5.3665	Acc@1 66.239	Acc@5 91.294
Epoch: [14][400/782]	GPU 0	Time: 7.082	Loss 5.3683	Acc@1 66.233	Acc@5 91.373
Epoch: [14][600/782]	GPU 0	Time: 10.457	Loss 5.3876	Acc@1 66.124	Acc@5 91.085
 * Epoch 14, GPU 0, Acc@1 65.934, Acc@5 90.946, Time 26.73
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.124	Loss 1.5871	Acc@1 62.500	Acc@5 81.250
Test: [200/313]	GPU: 0	Time: 0.582	Loss 1.8183	Acc@1 57.338	Acc@5 85.339
 ** Acc@1 57.830, Acc@5 85.570
==> training...
Epoch: [15][0/782]	GPU 0	Time: 0.262	Loss 5.6508	Acc@1 75.000	Acc@5 90.625
Epoch: [15][200/782]	GPU 0	Time: 3.663	Loss 5.2847	Acc@1 67.374	Acc@5 91.208
Epoch: [15][400/782]	GPU 0	Time: 7.052	Loss 5.2586	Acc@1 67.113	Acc@5 91.334
Epoch: [15][600/782]	GPU 0	Time: 10.436	Loss 5.2811	Acc@1 66.816	Acc@5 91.275
 * Epoch 15, GPU 0, Acc@1 66.810, Acc@5 91.272, Time 26.73
GPU 0 validating
2024/05/15 08:52:53 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under mlflow-artifacts:/2/77b785ebc142440dad9756db7b3e5449/artifacts. Set logging level to DEBUG via `logging.getLogger("mlflow").setLevel(logging.DEBUG)` to see the full traceback.
Test: [0/313]	GPU: 0	Time: 0.128	Loss 1.4153	Acc@1 68.750	Acc@5 81.250
Test: [200/313]	GPU: 0	Time: 0.577	Loss 1.6678	Acc@1 59.857	Acc@5 87.578
 ** Acc@1 59.860, Acc@5 87.520
saving the best model!
==> training...
Epoch: [16][0/782]	GPU 0	Time: 0.279	Loss 4.7575	Acc@1 70.312	Acc@5 95.312
Epoch: [16][200/782]	GPU 0	Time: 3.721	Loss 5.0583	Acc@1 68.105	Acc@5 91.915
Epoch: [16][400/782]	GPU 0	Time: 7.102	Loss 5.0910	Acc@1 68.064	Acc@5 91.856
Epoch: [16][600/782]	GPU 0	Time: 10.485	Loss 5.1163	Acc@1 67.913	Acc@5 91.863
 * Epoch 16, GPU 0, Acc@1 67.810, Acc@5 91.826, Time 26.80
GPU 0 validating
2024/05/15 08:53:26 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under mlflow-artifacts:/2/77b785ebc142440dad9756db7b3e5449/artifacts. Set logging level to DEBUG via `logging.getLogger("mlflow").setLevel(logging.DEBUG)` to see the full traceback.
Test: [0/313]	GPU: 0	Time: 0.126	Loss 1.4789	Acc@1 65.625	Acc@5 81.250
Test: [200/313]	GPU: 0	Time: 0.590	Loss 1.5878	Acc@1 60.914	Acc@5 87.780
 ** Acc@1 61.250, Acc@5 87.880
saving the best model!
==> training...
Epoch: [17][0/782]	GPU 0	Time: 0.276	Loss 4.8521	Acc@1 76.562	Acc@5 95.312
Epoch: [17][200/782]	GPU 0	Time: 3.704	Loss 4.9053	Acc@1 69.621	Acc@5 92.724
Epoch: [17][400/782]	GPU 0	Time: 7.077	Loss 4.9610	Acc@1 69.409	Acc@5 92.456
Epoch: [17][600/782]	GPU 0	Time: 10.452	Loss 4.9668	Acc@1 69.132	Acc@5 92.382
 * Epoch 17, GPU 0, Acc@1 68.884, Acc@5 92.116, Time 26.75
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.122	Loss 1.7250	Acc@1 65.625	Acc@5 84.375
Test: [200/313]	GPU: 0	Time: 0.578	Loss 1.6797	Acc@1 60.728	Acc@5 86.909
 ** Acc@1 60.900, Acc@5 86.910
==> training...
Epoch: [18][0/782]	GPU 0	Time: 0.256	Loss 5.9274	Acc@1 65.625	Acc@5 85.938
Epoch: [18][200/782]	GPU 0	Time: 3.646	Loss 4.8598	Acc@1 70.398	Acc@5 93.089
Epoch: [18][400/782]	GPU 0	Time: 7.037	Loss 4.8691	Acc@1 69.950	Acc@5 92.869
Epoch: [18][600/782]	GPU 0	Time: 10.421	Loss 4.8971	Acc@1 69.483	Acc@5 92.736
 * Epoch 18, GPU 0, Acc@1 69.340, Acc@5 92.676, Time 26.73
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.125	Loss 1.3672	Acc@1 75.000	Acc@5 90.625
Test: [200/313]	GPU: 0	Time: 0.587	Loss 1.6271	Acc@1 61.007	Acc@5 87.127
 ** Acc@1 60.460, Acc@5 87.180
==> training...
Epoch: [19][0/782]	GPU 0	Time: 0.256	Loss 4.6137	Acc@1 71.875	Acc@5 92.188
Epoch: [19][200/782]	GPU 0	Time: 3.645	Loss 4.7066	Acc@1 70.981	Acc@5 93.159
Epoch: [19][400/782]	GPU 0	Time: 7.032	Loss 4.7286	Acc@1 70.406	Acc@5 92.994
Epoch: [19][600/782]	GPU 0	Time: 10.433	Loss 4.7545	Acc@1 70.398	Acc@5 93.027
 * Epoch 19, GPU 0, Acc@1 70.244, Acc@5 92.908, Time 26.81
GPU 0 validating
2024/05/15 08:54:57 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under mlflow-artifacts:/2/77b785ebc142440dad9756db7b3e5449/artifacts. Set logging level to DEBUG via `logging.getLogger("mlflow").setLevel(logging.DEBUG)` to see the full traceback.
Test: [0/313]	GPU: 0	Time: 0.132	Loss 1.1471	Acc@1 71.875	Acc@5 87.500
Test: [200/313]	GPU: 0	Time: 0.609	Loss 1.5722	Acc@1 61.831	Acc@5 88.355
 ** Acc@1 62.100, Acc@5 88.380
saving the best model!
==> training...
Epoch: [20][0/782]	GPU 0	Time: 0.285	Loss 4.0753	Acc@1 71.875	Acc@5 90.625
Epoch: [20][200/782]	GPU 0	Time: 3.734	Loss 4.6220	Acc@1 70.896	Acc@5 93.151
Epoch: [20][400/782]	GPU 0	Time: 7.119	Loss 4.6425	Acc@1 71.065	Acc@5 93.150
Epoch: [20][600/782]	GPU 0	Time: 10.510	Loss 4.6605	Acc@1 71.027	Acc@5 93.227
 * Epoch 20, GPU 0, Acc@1 70.654, Acc@5 93.030, Time 26.91
GPU 0 validating
2024/05/15 08:55:31 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under mlflow-artifacts:/2/77b785ebc142440dad9756db7b3e5449/artifacts. Set logging level to DEBUG via `logging.getLogger("mlflow").setLevel(logging.DEBUG)` to see the full traceback.
Test: [0/313]	GPU: 0	Time: 0.130	Loss 1.4249	Acc@1 68.750	Acc@5 87.500
Test: [200/313]	GPU: 0	Time: 0.610	Loss 1.5510	Acc@1 62.158	Acc@5 88.806
 ** Acc@1 62.400, Acc@5 88.490
saving the best model!
==> training...
Epoch: [21][0/782]	GPU 0	Time: 0.352	Loss 4.2384	Acc@1 68.750	Acc@5 96.875
Epoch: [21][200/782]	GPU 0	Time: 3.845	Loss 4.5856	Acc@1 72.287	Acc@5 93.563
Epoch: [21][400/782]	GPU 0	Time: 7.264	Loss 4.6224	Acc@1 71.719	Acc@5 93.469
Epoch: [21][600/782]	GPU 0	Time: 10.663	Loss 4.6243	Acc@1 71.722	Acc@5 93.500
 * Epoch 21, GPU 0, Acc@1 71.534, Acc@5 93.378, Time 27.04
GPU 0 validating
2024/05/15 08:56:05 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under mlflow-artifacts:/2/77b785ebc142440dad9756db7b3e5449/artifacts. Set logging level to DEBUG via `logging.getLogger("mlflow").setLevel(logging.DEBUG)` to see the full traceback.
Test: [0/313]	GPU: 0	Time: 0.128	Loss 1.6554	Acc@1 59.375	Acc@5 84.375
Test: [200/313]	GPU: 0	Time: 0.594	Loss 1.5037	Acc@1 62.624	Acc@5 88.308
 ** Acc@1 62.690, Acc@5 88.450
saving the best model!
==> training...
Epoch: [22][0/782]	GPU 0	Time: 0.280	Loss 4.4201	Acc@1 68.750	Acc@5 95.312
Epoch: [22][200/782]	GPU 0	Time: 3.732	Loss 4.4829	Acc@1 72.559	Acc@5 94.030
Epoch: [22][400/782]	GPU 0	Time: 7.122	Loss 4.5035	Acc@1 72.385	Acc@5 93.836
Epoch: [22][600/782]	GPU 0	Time: 10.513	Loss 4.5289	Acc@1 72.174	Acc@5 93.706
 * Epoch 22, GPU 0, Acc@1 71.890, Acc@5 93.568, Time 26.88
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.119	Loss 1.2658	Acc@1 71.875	Acc@5 84.375
Test: [200/313]	GPU: 0	Time: 0.569	Loss 1.6163	Acc@1 61.863	Acc@5 88.044
 ** Acc@1 61.880, Acc@5 88.150
==> training...
Epoch: [23][0/782]	GPU 0	Time: 0.266	Loss 4.5819	Acc@1 76.562	Acc@5 92.188
Epoch: [23][200/782]	GPU 0	Time: 3.652	Loss 4.3976	Acc@1 73.313	Acc@5 93.859
Epoch: [23][400/782]	GPU 0	Time: 7.042	Loss 4.4523	Acc@1 72.592	Acc@5 93.758
Epoch: [23][600/782]	GPU 0	Time: 10.425	Loss 4.4937	Acc@1 72.395	Acc@5 93.797
 * Epoch 23, GPU 0, Acc@1 72.272, Acc@5 93.806, Time 26.94
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.124	Loss 1.6707	Acc@1 59.375	Acc@5 84.375
Test: [200/313]	GPU: 0	Time: 0.634	Loss 1.6589	Acc@1 60.743	Acc@5 87.065
 ** Acc@1 60.970, Acc@5 87.250
==> training...
Epoch: [24][0/782]	GPU 0	Time: 0.284	Loss 3.6203	Acc@1 79.688	Acc@5 95.312
Epoch: [24][200/782]	GPU 0	Time: 3.694	Loss 4.3231	Acc@1 73.694	Acc@5 94.465
Epoch: [24][400/782]	GPU 0	Time: 7.095	Loss 4.3467	Acc@1 73.391	Acc@5 94.307
Epoch: [24][600/782]	GPU 0	Time: 10.493	Loss 4.3798	Acc@1 73.240	Acc@5 94.267
 * Epoch 24, GPU 0, Acc@1 73.030, Acc@5 94.114, Time 26.86
GPU 0 validating
2024/05/15 08:57:36 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under mlflow-artifacts:/2/77b785ebc142440dad9756db7b3e5449/artifacts. Set logging level to DEBUG via `logging.getLogger("mlflow").setLevel(logging.DEBUG)` to see the full traceback.
Test: [0/313]	GPU: 0	Time: 0.120	Loss 1.3797	Acc@1 68.750	Acc@5 84.375
Test: [200/313]	GPU: 0	Time: 0.570	Loss 1.5398	Acc@1 62.858	Acc@5 89.101
 ** Acc@1 62.760, Acc@5 89.050
saving the best model!
==> training...
Epoch: [25][0/782]	GPU 0	Time: 0.283	Loss 3.5546	Acc@1 85.938	Acc@5 96.875
Epoch: [25][200/782]	GPU 0	Time: 3.725	Loss 4.3084	Acc@1 74.378	Acc@5 94.551
Epoch: [25][400/782]	GPU 0	Time: 7.123	Loss 4.3577	Acc@1 73.823	Acc@5 94.303
Epoch: [25][600/782]	GPU 0	Time: 10.549	Loss 4.3791	Acc@1 73.521	Acc@5 94.257
 * Epoch 25, GPU 0, Acc@1 73.170, Acc@5 94.140, Time 27.04
GPU 0 validating
2024/05/15 08:58:10 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under mlflow-artifacts:/2/77b785ebc142440dad9756db7b3e5449/artifacts. Set logging level to DEBUG via `logging.getLogger("mlflow").setLevel(logging.DEBUG)` to see the full traceback.
Test: [0/313]	GPU: 0	Time: 0.128	Loss 1.3550	Acc@1 65.625	Acc@5 84.375
Test: [200/313]	GPU: 0	Time: 0.589	Loss 1.4678	Acc@1 63.993	Acc@5 89.288
 ** Acc@1 63.900, Acc@5 89.120
saving the best model!
==> training...
Epoch: [26][0/782]	GPU 0	Time: 0.343	Loss 3.9792	Acc@1 78.125	Acc@5 95.312
Epoch: [26][200/782]	GPU 0	Time: 3.795	Loss 4.2103	Acc@1 74.930	Acc@5 94.691
Epoch: [26][400/782]	GPU 0	Time: 7.179	Loss 4.2346	Acc@1 74.264	Acc@5 94.658
Epoch: [26][600/782]	GPU 0	Time: 10.568	Loss 4.2803	Acc@1 73.879	Acc@5 94.413
 * Epoch 26, GPU 0, Acc@1 73.632, Acc@5 94.296, Time 26.87
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.122	Loss 1.2376	Acc@1 71.875	Acc@5 87.500
Test: [200/313]	GPU: 0	Time: 0.571	Loss 1.4780	Acc@1 63.650	Acc@5 89.210
 ** Acc@1 63.620, Acc@5 88.990
==> training...
Epoch: [27][0/782]	GPU 0	Time: 0.263	Loss 4.0610	Acc@1 79.688	Acc@5 96.875
Epoch: [27][200/782]	GPU 0	Time: 3.644	Loss 4.1491	Acc@1 75.000	Acc@5 94.916
Epoch: [27][400/782]	GPU 0	Time: 7.027	Loss 4.2302	Acc@1 74.466	Acc@5 94.611
Epoch: [27][600/782]	GPU 0	Time: 10.411	Loss 4.2505	Acc@1 74.217	Acc@5 94.546
 * Epoch 27, GPU 0, Acc@1 74.042, Acc@5 94.482, Time 26.73
GPU 0 validating
2024/05/15 08:59:12 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under mlflow-artifacts:/2/77b785ebc142440dad9756db7b3e5449/artifacts. Set logging level to DEBUG via `logging.getLogger("mlflow").setLevel(logging.DEBUG)` to see the full traceback.
Test: [0/313]	GPU: 0	Time: 0.120	Loss 1.5303	Acc@1 68.750	Acc@5 84.375
Test: [200/313]	GPU: 0	Time: 0.585	Loss 1.4495	Acc@1 64.443	Acc@5 89.568
 ** Acc@1 64.840, Acc@5 89.540
saving the best model!
==> training...
Epoch: [28][0/782]	GPU 0	Time: 0.291	Loss 3.9429	Acc@1 84.375	Acc@5 96.875
Epoch: [28][200/782]	GPU 0	Time: 3.751	Loss 4.1528	Acc@1 75.358	Acc@5 94.994
Epoch: [28][400/782]	GPU 0	Time: 7.147	Loss 4.2083	Acc@1 74.747	Acc@5 94.818
Epoch: [28][600/782]	GPU 0	Time: 10.533	Loss 4.2203	Acc@1 74.568	Acc@5 94.738
 * Epoch 28, GPU 0, Acc@1 74.530, Acc@5 94.630, Time 26.84
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.127	Loss 1.1094	Acc@1 75.000	Acc@5 90.625
Test: [200/313]	GPU: 0	Time: 0.602	Loss 1.4688	Acc@1 64.024	Acc@5 89.490
 ** Acc@1 63.490, Acc@5 89.310
==> training...
Epoch: [29][0/782]	GPU 0	Time: 0.259	Loss 3.9153	Acc@1 79.688	Acc@5 93.750
Epoch: [29][200/782]	GPU 0	Time: 3.643	Loss 4.0973	Acc@1 75.482	Acc@5 94.823
Epoch: [29][400/782]	GPU 0	Time: 7.032	Loss 4.1383	Acc@1 75.023	Acc@5 94.833
Epoch: [29][600/782]	GPU 0	Time: 10.419	Loss 4.1645	Acc@1 75.075	Acc@5 94.764
 * Epoch 29, GPU 0, Acc@1 74.672, Acc@5 94.672, Time 26.80
GPU 0 validating
2024/05/15 09:00:14 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under mlflow-artifacts:/2/77b785ebc142440dad9756db7b3e5449/artifacts. Set logging level to DEBUG via `logging.getLogger("mlflow").setLevel(logging.DEBUG)` to see the full traceback.
Test: [0/313]	GPU: 0	Time: 0.126	Loss 1.1930	Acc@1 71.875	Acc@5 87.500
Test: [200/313]	GPU: 0	Time: 0.582	Loss 1.3832	Acc@1 65.641	Acc@5 89.677
 ** Acc@1 65.700, Acc@5 89.630
saving the best model!
==> training...
Epoch: [30][0/782]	GPU 0	Time: 0.275	Loss 3.4244	Acc@1 73.438	Acc@5 98.438
Epoch: [30][200/782]	GPU 0	Time: 3.696	Loss 4.1025	Acc@1 75.459	Acc@5 95.025
Epoch: [30][400/782]	GPU 0	Time: 7.074	Loss 4.1535	Acc@1 74.719	Acc@5 94.884
Epoch: [30][600/782]	GPU 0	Time: 10.454	Loss 4.1581	Acc@1 74.867	Acc@5 94.860
 * Epoch 30, GPU 0, Acc@1 74.738, Acc@5 94.898, Time 26.76
GPU 0 validating
2024/05/15 09:00:48 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under mlflow-artifacts:/2/77b785ebc142440dad9756db7b3e5449/artifacts. Set logging level to DEBUG via `logging.getLogger("mlflow").setLevel(logging.DEBUG)` to see the full traceback.
Test: [0/313]	GPU: 0	Time: 0.125	Loss 1.2983	Acc@1 65.625	Acc@5 90.625
Test: [200/313]	GPU: 0	Time: 0.579	Loss 1.3919	Acc@1 65.858	Acc@5 90.143
 ** Acc@1 65.770, Acc@5 90.150
saving the best model!
==> training...
Epoch: [31][0/782]	GPU 0	Time: 0.272	Loss 4.4886	Acc@1 71.875	Acc@5 95.312
Epoch: [31][200/782]	GPU 0	Time: 3.682	Loss 3.9891	Acc@1 76.353	Acc@5 95.196
Epoch: [31][400/782]	GPU 0	Time: 7.060	Loss 4.0488	Acc@1 75.846	Acc@5 95.164
Epoch: [31][600/782]	GPU 0	Time: 10.449	Loss 4.0779	Acc@1 75.549	Acc@5 95.097
 * Epoch 31, GPU 0, Acc@1 75.334, Acc@5 94.984, Time 26.91
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.161	Loss 1.3871	Acc@1 65.625	Acc@5 87.500
Test: [200/313]	GPU: 0	Time: 0.650	Loss 1.6009	Acc@1 63.060	Acc@5 88.775
 ** Acc@1 62.710, Acc@5 88.580
==> training...
Epoch: [32][0/782]	GPU 0	Time: 0.332	Loss 3.4824	Acc@1 71.875	Acc@5 93.750
Epoch: [32][200/782]	GPU 0	Time: 4.912	Loss 3.9858	Acc@1 76.252	Acc@5 95.351
Epoch: [32][400/782]	GPU 0	Time: 9.188	Loss 4.0277	Acc@1 76.021	Acc@5 95.211
Epoch: [32][600/782]	GPU 0	Time: 12.878	Loss 4.0677	Acc@1 75.595	Acc@5 95.167
 * Epoch 32, GPU 0, Acc@1 75.334, Acc@5 95.060, Time 29.81
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.128	Loss 1.2912	Acc@1 71.875	Acc@5 90.625
Test: [200/313]	GPU: 0	Time: 0.568	Loss 1.4397	Acc@1 64.599	Acc@5 89.521
 ** Acc@1 64.360, Acc@5 89.200
==> training...
Epoch: [33][0/782]	GPU 0	Time: 0.252	Loss 3.3533	Acc@1 73.438	Acc@5 96.875
Epoch: [33][200/782]	GPU 0	Time: 3.638	Loss 3.9469	Acc@1 76.461	Acc@5 95.655
Epoch: [33][400/782]	GPU 0	Time: 7.020	Loss 3.9844	Acc@1 76.485	Acc@5 95.367
Epoch: [33][600/782]	GPU 0	Time: 10.403	Loss 4.0284	Acc@1 76.089	Acc@5 95.261
 * Epoch 33, GPU 0, Acc@1 75.746, Acc@5 95.200, Time 28.19
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.118	Loss 0.9083	Acc@1 78.125	Acc@5 90.625
Test: [200/313]	GPU: 0	Time: 0.560	Loss 1.3910	Acc@1 65.127	Acc@5 89.319
 ** Acc@1 65.040, Acc@5 89.280
==> training...
Epoch: [34][0/782]	GPU 0	Time: 0.263	Loss 4.5394	Acc@1 73.438	Acc@5 92.188
Epoch: [34][200/782]	GPU 0	Time: 3.784	Loss 3.9319	Acc@1 76.469	Acc@5 95.476
Epoch: [34][400/782]	GPU 0	Time: 7.192	Loss 4.0020	Acc@1 75.947	Acc@5 95.328
Epoch: [34][600/782]	GPU 0	Time: 10.583	Loss 4.0179	Acc@1 75.991	Acc@5 95.250
 * Epoch 34, GPU 0, Acc@1 75.722, Acc@5 95.134, Time 26.93
GPU 0 validating
2024/05/15 09:02:48 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpp9odcjr2/model/data, flavor: pytorch). Fall back to return ['torch==1.11.0', 'cloudpickle==3.0.0']. Set logging level to DEBUG to see the full traceback. 
2024/05/15 09:02:48 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under mlflow-artifacts:/2/77b785ebc142440dad9756db7b3e5449/artifacts. Set logging level to DEBUG via `logging.getLogger("mlflow").setLevel(logging.DEBUG)` to see the full traceback.
Test: [0/313]	GPU: 0	Time: 0.123	Loss 1.2513	Acc@1 68.750	Acc@5 84.375
Test: [200/313]	GPU: 0	Time: 0.568	Loss 1.4040	Acc@1 65.905	Acc@5 89.397
 ** Acc@1 66.140, Acc@5 89.320
saving the best model!
==> training...
Epoch: [35][0/782]	GPU 0	Time: 0.282	Loss 3.6091	Acc@1 84.375	Acc@5 96.875
Epoch: [35][200/782]	GPU 0	Time: 3.716	Loss 3.9228	Acc@1 76.749	Acc@5 95.631
Epoch: [35][400/782]	GPU 0	Time: 7.115	Loss 3.9423	Acc@1 76.555	Acc@5 95.562
Epoch: [35][600/782]	GPU 0	Time: 10.516	Loss 3.9674	Acc@1 76.316	Acc@5 95.401
 * Epoch 35, GPU 0, Acc@1 76.046, Acc@5 95.324, Time 26.86
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.129	Loss 1.4478	Acc@1 68.750	Acc@5 81.250
Test: [200/313]	GPU: 0	Time: 0.585	Loss 1.4866	Acc@1 64.288	Acc@5 88.993
 ** Acc@1 64.510, Acc@5 89.000
==> training...
Epoch: [36][0/782]	GPU 0	Time: 0.262	Loss 4.5161	Acc@1 73.438	Acc@5 92.188
Epoch: [36][200/782]	GPU 0	Time: 3.673	Loss 3.8492	Acc@1 77.565	Acc@5 95.686
Epoch: [36][400/782]	GPU 0	Time: 7.062	Loss 3.9051	Acc@1 76.983	Acc@5 95.659
Epoch: [36][600/782]	GPU 0	Time: 10.450	Loss 3.9290	Acc@1 76.695	Acc@5 95.463
 * Epoch 36, GPU 0, Acc@1 76.456, Acc@5 95.364, Time 26.80
GPU 0 validating
2024/05/15 09:03:51 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under mlflow-artifacts:/2/77b785ebc142440dad9756db7b3e5449/artifacts. Set logging level to DEBUG via `logging.getLogger("mlflow").setLevel(logging.DEBUG)` to see the full traceback.
Test: [0/313]	GPU: 0	Time: 0.126	Loss 1.0040	Acc@1 78.125	Acc@5 87.500
Test: [200/313]	GPU: 0	Time: 0.586	Loss 1.3951	Acc@1 66.340	Acc@5 89.646
 ** Acc@1 66.360, Acc@5 89.620
saving the best model!
==> training...
Epoch: [37][0/782]	GPU 0	Time: 0.299	Loss 3.8693	Acc@1 79.688	Acc@5 96.875
Epoch: [37][200/782]	GPU 0	Time: 4.001	Loss 3.8112	Acc@1 77.511	Acc@5 95.818
Epoch: [37][400/782]	GPU 0	Time: 8.804	Loss 3.8627	Acc@1 77.166	Acc@5 95.757
Epoch: [37][600/782]	GPU 0	Time: 12.781	Loss 3.9059	Acc@1 76.718	Acc@5 95.640
 * Epoch 37, GPU 0, Acc@1 76.538, Acc@5 95.508, Time 31.98
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.125	Loss 1.3678	Acc@1 78.125	Acc@5 84.375
Test: [200/313]	GPU: 0	Time: 0.597	Loss 1.4718	Acc@1 65.998	Acc@5 89.692
 ** Acc@1 66.150, Acc@5 89.700
==> training...
Epoch: [38][0/782]	GPU 0	Time: 0.286	Loss 4.1454	Acc@1 78.125	Acc@5 95.312
Epoch: [38][200/782]	GPU 0	Time: 3.651	Loss 3.8194	Acc@1 77.589	Acc@5 95.647
Epoch: [38][400/782]	GPU 0	Time: 7.101	Loss 3.8464	Acc@1 77.669	Acc@5 95.803
Epoch: [38][600/782]	GPU 0	Time: 10.515	Loss 3.8778	Acc@1 77.483	Acc@5 95.632
 * Epoch 38, GPU 0, Acc@1 77.048, Acc@5 95.458, Time 26.89
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.127	Loss 1.2289	Acc@1 65.625	Acc@5 87.500
Test: [200/313]	GPU: 0	Time: 0.591	Loss 1.4214	Acc@1 65.641	Acc@5 89.739
 ** Acc@1 65.420, Acc@5 89.690
==> training...
Epoch: [39][0/782]	GPU 0	Time: 0.274	Loss 4.6054	Acc@1 68.750	Acc@5 93.750
Epoch: [39][200/782]	GPU 0	Time: 3.664	Loss 3.8170	Acc@1 77.534	Acc@5 95.701
Epoch: [39][400/782]	GPU 0	Time: 7.053	Loss 3.8518	Acc@1 77.042	Acc@5 95.605
Epoch: [39][600/782]	GPU 0	Time: 10.444	Loss 3.8860	Acc@1 76.835	Acc@5 95.489
 * Epoch 39, GPU 0, Acc@1 76.770, Acc@5 95.506, Time 26.78
GPU 0 validating
2024/05/15 09:05:23 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpp1cfwgdu/model/data, flavor: pytorch). Fall back to return ['torch==1.11.0', 'cloudpickle==3.0.0']. Set logging level to DEBUG to see the full traceback. 
2024/05/15 09:05:24 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under mlflow-artifacts:/2/77b785ebc142440dad9756db7b3e5449/artifacts. Set logging level to DEBUG via `logging.getLogger("mlflow").setLevel(logging.DEBUG)` to see the full traceback.
Test: [0/313]	GPU: 0	Time: 0.124	Loss 1.1139	Acc@1 75.000	Acc@5 93.750
Test: [200/313]	GPU: 0	Time: 0.572	Loss 1.3676	Acc@1 66.542	Acc@5 90.734
 ** Acc@1 66.680, Acc@5 90.610
saving the best model!
==> training...
Epoch: [40][0/782]	GPU 0	Time: 0.292	Loss 3.8466	Acc@1 79.688	Acc@5 96.875
Epoch: [40][200/782]	GPU 0	Time: 3.736	Loss 3.8108	Acc@1 77.970	Acc@5 96.175
Epoch: [40][400/782]	GPU 0	Time: 7.114	Loss 3.8466	Acc@1 77.342	Acc@5 95.846
Epoch: [40][600/782]	GPU 0	Time: 10.490	Loss 3.8629	Acc@1 77.264	Acc@5 95.780
 * Epoch 40, GPU 0, Acc@1 77.042, Acc@5 95.630, Time 26.78
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.124	Loss 1.3646	Acc@1 68.750	Acc@5 84.375
Test: [200/313]	GPU: 0	Time: 0.588	Loss 1.4339	Acc@1 65.827	Acc@5 89.692
 ** Acc@1 66.200, Acc@5 89.640
==> training...
Epoch: [41][0/782]	GPU 0	Time: 0.290	Loss 3.6926	Acc@1 82.812	Acc@5 93.750
Epoch: [41][200/782]	GPU 0	Time: 3.666	Loss 3.7796	Acc@1 78.444	Acc@5 96.098
Epoch: [41][400/782]	GPU 0	Time: 7.044	Loss 3.8075	Acc@1 77.864	Acc@5 96.045
Epoch: [41][600/782]	GPU 0	Time: 10.429	Loss 3.8342	Acc@1 77.465	Acc@5 95.903
 * Epoch 41, GPU 0, Acc@1 77.198, Acc@5 95.794, Time 26.74
GPU 0 validating
2024/05/15 09:06:26 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under mlflow-artifacts:/2/77b785ebc142440dad9756db7b3e5449/artifacts. Set logging level to DEBUG via `logging.getLogger("mlflow").setLevel(logging.DEBUG)` to see the full traceback.
Test: [0/313]	GPU: 0	Time: 0.120	Loss 1.2728	Acc@1 68.750	Acc@5 87.500
Test: [200/313]	GPU: 0	Time: 0.572	Loss 1.3786	Acc@1 66.465	Acc@5 90.407
 ** Acc@1 66.850, Acc@5 90.250
saving the best model!
==> training...
Epoch: [42][0/782]	GPU 0	Time: 0.273	Loss 4.2297	Acc@1 75.000	Acc@5 96.875
Epoch: [42][200/782]	GPU 0	Time: 3.710	Loss 3.7618	Acc@1 78.016	Acc@5 96.012
Epoch: [42][400/782]	GPU 0	Time: 7.085	Loss 3.8050	Acc@1 77.591	Acc@5 95.948
Epoch: [42][600/782]	GPU 0	Time: 10.465	Loss 3.8353	Acc@1 77.379	Acc@5 95.853
 * Epoch 42, GPU 0, Acc@1 77.188, Acc@5 95.854, Time 26.73
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.131	Loss 1.1818	Acc@1 65.625	Acc@5 87.500
Test: [200/313]	GPU: 0	Time: 0.566	Loss 1.5400	Acc@1 64.381	Acc@5 88.511
 ** Acc@1 64.550, Acc@5 88.290
==> training...
Epoch: [43][0/782]	GPU 0	Time: 0.256	Loss 3.3788	Acc@1 82.812	Acc@5 100.000
Epoch: [43][200/782]	GPU 0	Time: 3.636	Loss 3.7332	Acc@1 77.970	Acc@5 95.934
Epoch: [43][400/782]	GPU 0	Time: 7.016	Loss 3.7460	Acc@1 78.016	Acc@5 95.944
Epoch: [43][600/782]	GPU 0	Time: 10.393	Loss 3.7745	Acc@1 77.686	Acc@5 95.879
 * Epoch 43, GPU 0, Acc@1 77.532, Acc@5 95.822, Time 26.68
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.120	Loss 1.4017	Acc@1 75.000	Acc@5 81.250
Test: [200/313]	GPU: 0	Time: 0.565	Loss 1.4537	Acc@1 64.785	Acc@5 89.661
 ** Acc@1 64.980, Acc@5 89.500
==> training...
Epoch: [44][0/782]	GPU 0	Time: 0.261	Loss 4.3945	Acc@1 79.688	Acc@5 95.312
Epoch: [44][200/782]	GPU 0	Time: 3.642	Loss 3.6747	Acc@1 78.646	Acc@5 96.479
Epoch: [44][400/782]	GPU 0	Time: 7.022	Loss 3.7419	Acc@1 78.176	Acc@5 96.119
Epoch: [44][600/782]	GPU 0	Time: 10.402	Loss 3.7793	Acc@1 77.790	Acc@5 95.908
 * Epoch 44, GPU 0, Acc@1 77.608, Acc@5 95.808, Time 26.71
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.125	Loss 1.1653	Acc@1 71.875	Acc@5 84.375
Test: [200/313]	GPU: 0	Time: 0.585	Loss 1.4036	Acc@1 65.609	Acc@5 89.863
 ** Acc@1 65.790, Acc@5 89.960
==> training...
Epoch: [45][0/782]	GPU 0	Time: 0.271	Loss 3.7658	Acc@1 82.812	Acc@5 98.438
Epoch: [45][200/782]	GPU 0	Time: 3.668	Loss 3.7198	Acc@1 78.584	Acc@5 95.989
Epoch: [45][400/782]	GPU 0	Time: 7.998	Loss 3.7286	Acc@1 78.246	Acc@5 96.002
Epoch: [45][600/782]	GPU 0	Time: 12.140	Loss 3.7595	Acc@1 78.169	Acc@5 95.903
 * Epoch 45, GPU 0, Acc@1 77.940, Acc@5 95.890, Time 29.98
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.124	Loss 1.4011	Acc@1 68.750	Acc@5 81.250
Test: [200/313]	GPU: 0	Time: 0.595	Loss 1.4954	Acc@1 65.003	Acc@5 89.443
 ** Acc@1 65.130, Acc@5 89.310
==> training...
Epoch: [46][0/782]	GPU 0	Time: 0.262	Loss 3.6008	Acc@1 81.250	Acc@5 100.000
Epoch: [46][200/782]	GPU 0	Time: 3.657	Loss 3.6476	Acc@1 78.716	Acc@5 96.245
Epoch: [46][400/782]	GPU 0	Time: 7.047	Loss 3.6915	Acc@1 78.468	Acc@5 96.111
Epoch: [46][600/782]	GPU 0	Time: 10.439	Loss 3.7352	Acc@1 78.133	Acc@5 95.996
 * Epoch 46, GPU 0, Acc@1 77.990, Acc@5 95.994, Time 26.80
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.131	Loss 0.9500	Acc@1 71.875	Acc@5 93.750
Test: [200/313]	GPU: 0	Time: 0.587	Loss 1.4018	Acc@1 65.516	Acc@5 89.941
 ** Acc@1 65.740, Acc@5 90.110
==> training...
Epoch: [47][0/782]	GPU 0	Time: 0.271	Loss 3.8221	Acc@1 79.688	Acc@5 98.438
Epoch: [47][200/782]	GPU 0	Time: 3.666	Loss 3.6863	Acc@1 78.700	Acc@5 96.082
Epoch: [47][400/782]	GPU 0	Time: 7.066	Loss 3.6975	Acc@1 78.643	Acc@5 96.123
Epoch: [47][600/782]	GPU 0	Time: 10.459	Loss 3.7410	Acc@1 78.234	Acc@5 96.137
 * Epoch 47, GPU 0, Acc@1 77.954, Acc@5 96.056, Time 26.83
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.127	Loss 1.2109	Acc@1 68.750	Acc@5 93.750
Test: [200/313]	GPU: 0	Time: 0.602	Loss 1.3678	Acc@1 66.807	Acc@5 90.159
 ** Acc@1 66.800, Acc@5 89.970
==> training...
Epoch: [48][0/782]	GPU 0	Time: 0.281	Loss 4.1302	Acc@1 85.938	Acc@5 98.438
Epoch: [48][200/782]	GPU 0	Time: 3.682	Loss 3.5946	Acc@1 79.757	Acc@5 96.650
Epoch: [48][400/782]	GPU 0	Time: 7.070	Loss 3.6788	Acc@1 78.873	Acc@5 96.248
Epoch: [48][600/782]	GPU 0	Time: 10.457	Loss 3.7111	Acc@1 78.481	Acc@5 96.165
 * Epoch 48, GPU 0, Acc@1 78.160, Acc@5 96.106, Time 26.78
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.125	Loss 1.1396	Acc@1 68.750	Acc@5 87.500
Test: [200/313]	GPU: 0	Time: 0.607	Loss 1.4477	Acc@1 65.423	Acc@5 89.070
 ** Acc@1 65.550, Acc@5 89.140
==> training...
Epoch: [49][0/782]	GPU 0	Time: 0.268	Loss 3.4382	Acc@1 73.438	Acc@5 95.312
Epoch: [49][200/782]	GPU 0	Time: 3.655	Loss 3.6254	Acc@1 78.980	Acc@5 96.276
Epoch: [49][400/782]	GPU 0	Time: 7.034	Loss 3.6388	Acc@1 78.873	Acc@5 96.329
Epoch: [49][600/782]	GPU 0	Time: 10.416	Loss 3.7058	Acc@1 78.271	Acc@5 96.129
 * Epoch 49, GPU 0, Acc@1 78.124, Acc@5 96.090, Time 26.74
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.128	Loss 1.1250	Acc@1 75.000	Acc@5 93.750
Test: [200/313]	GPU: 0	Time: 0.582	Loss 1.4731	Acc@1 65.174	Acc@5 88.822
 ** Acc@1 65.160, Acc@5 89.000
==> training...
Epoch: [50][0/782]	GPU 0	Time: 0.264	Loss 4.3317	Acc@1 76.562	Acc@5 92.188
Epoch: [50][200/782]	GPU 0	Time: 3.645	Loss 3.6136	Acc@1 79.408	Acc@5 96.129
Epoch: [50][400/782]	GPU 0	Time: 7.034	Loss 3.6412	Acc@1 78.854	Acc@5 96.209
Epoch: [50][600/782]	GPU 0	Time: 10.415	Loss 3.6719	Acc@1 78.707	Acc@5 96.199
 * Epoch 50, GPU 0, Acc@1 78.474, Acc@5 96.122, Time 26.71
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.126	Loss 1.4539	Acc@1 71.875	Acc@5 81.250
Test: [200/313]	GPU: 0	Time: 0.597	Loss 1.4287	Acc@1 65.827	Acc@5 89.910
 ** Acc@1 66.160, Acc@5 89.920
==> training...
Epoch: [51][0/782]	GPU 0	Time: 0.267	Loss 3.3707	Acc@1 78.125	Acc@5 95.312
Epoch: [51][200/782]	GPU 0	Time: 3.649	Loss 3.5942	Acc@1 79.314	Acc@5 96.650
Epoch: [51][400/782]	GPU 0	Time: 7.029	Loss 3.6366	Acc@1 78.959	Acc@5 96.368
Epoch: [51][600/782]	GPU 0	Time: 10.573	Loss 3.6739	Acc@1 78.510	Acc@5 96.267
 * Epoch 51, GPU 0, Acc@1 78.276, Acc@5 96.158, Time 28.19
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.126	Loss 1.4398	Acc@1 68.750	Acc@5 84.375
Test: [200/313]	GPU: 0	Time: 0.596	Loss 1.4273	Acc@1 65.998	Acc@5 90.454
 ** Acc@1 66.460, Acc@5 90.580
==> training...
Epoch: [52][0/782]	GPU 0	Time: 0.274	Loss 3.5605	Acc@1 82.812	Acc@5 96.875
Epoch: [52][200/782]	GPU 0	Time: 3.687	Loss 3.5623	Acc@1 79.843	Acc@5 96.595
Epoch: [52][400/782]	GPU 0	Time: 7.076	Loss 3.6028	Acc@1 79.442	Acc@5 96.598
Epoch: [52][600/782]	GPU 0	Time: 10.473	Loss 3.6437	Acc@1 79.064	Acc@5 96.339
 * Epoch 52, GPU 0, Acc@1 78.782, Acc@5 96.258, Time 26.90
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.140	Loss 1.1328	Acc@1 68.750	Acc@5 84.375
Test: [200/313]	GPU: 0	Time: 0.608	Loss 1.6635	Acc@1 62.516	Acc@5 88.448
 ** Acc@1 62.760, Acc@5 88.320
==> training...
Epoch: [53][0/782]	GPU 0	Time: 0.265	Loss 3.7083	Acc@1 81.250	Acc@5 93.750
Epoch: [53][200/782]	GPU 0	Time: 3.663	Loss 3.6110	Acc@1 78.949	Acc@5 96.447
Epoch: [53][400/782]	GPU 0	Time: 7.083	Loss 3.6237	Acc@1 79.072	Acc@5 96.333
Epoch: [53][600/782]	GPU 0	Time: 10.533	Loss 3.6591	Acc@1 78.850	Acc@5 96.191
 * Epoch 53, GPU 0, Acc@1 78.510, Acc@5 96.192, Time 27.01
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.125	Loss 1.4085	Acc@1 59.375	Acc@5 87.500
Test: [200/313]	GPU: 0	Time: 0.600	Loss 1.5126	Acc@1 64.956	Acc@5 89.179
 ** Acc@1 65.170, Acc@5 89.090
==> training...
Epoch: [54][0/782]	GPU 0	Time: 0.320	Loss 3.5417	Acc@1 76.562	Acc@5 92.188
Epoch: [54][200/782]	GPU 0	Time: 3.716	Loss 3.6255	Acc@1 79.167	Acc@5 96.549
Epoch: [54][400/782]	GPU 0	Time: 7.104	Loss 3.6432	Acc@1 79.033	Acc@5 96.466
Epoch: [54][600/782]	GPU 0	Time: 10.492	Loss 3.6648	Acc@1 78.772	Acc@5 96.332
 * Epoch 54, GPU 0, Acc@1 78.612, Acc@5 96.284, Time 26.82
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.140	Loss 1.2641	Acc@1 68.750	Acc@5 90.625
Test: [200/313]	GPU: 0	Time: 0.613	Loss 1.4525	Acc@1 65.516	Acc@5 89.412
 ** Acc@1 65.860, Acc@5 89.520
==> training...
Epoch: [55][0/782]	GPU 0	Time: 0.278	Loss 3.5522	Acc@1 81.250	Acc@5 96.875
Epoch: [55][200/782]	GPU 0	Time: 3.694	Loss 3.5688	Acc@1 79.555	Acc@5 96.572
Epoch: [55][400/782]	GPU 0	Time: 7.079	Loss 3.5991	Acc@1 79.095	Acc@5 96.466
Epoch: [55][600/782]	GPU 0	Time: 10.463	Loss 3.6125	Acc@1 79.175	Acc@5 96.462
 * Epoch 55, GPU 0, Acc@1 78.924, Acc@5 96.338, Time 26.81
GPU 0 validating
2024/05/15 09:13:12 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmpwysdkq3a/model/data, flavor: pytorch). Fall back to return ['torch==1.11.0', 'cloudpickle==3.0.0']. Set logging level to DEBUG to see the full traceback. 
2024/05/15 09:13:12 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed. The model artifacts have been logged successfully under mlflow-artifacts:/2/77b785ebc142440dad9756db7b3e5449/artifacts. Set logging level to DEBUG via `logging.getLogger("mlflow").setLevel(logging.DEBUG)` to see the full traceback.
Test: [0/313]	GPU: 0	Time: 0.122	Loss 1.1966	Acc@1 75.000	Acc@5 84.375
Test: [200/313]	GPU: 0	Time: 0.580	Loss 1.3664	Acc@1 67.133	Acc@5 90.345
 ** Acc@1 67.010, Acc@5 90.520
saving the best model!
==> training...
Epoch: [56][0/782]	GPU 0	Time: 0.269	Loss 4.0985	Acc@1 76.562	Acc@5 93.750
Epoch: [56][200/782]	GPU 0	Time: 3.868	Loss 3.5522	Acc@1 79.882	Acc@5 96.650
Epoch: [56][400/782]	GPU 0	Time: 7.328	Loss 3.5809	Acc@1 79.641	Acc@5 96.517
Epoch: [56][600/782]	GPU 0	Time: 10.735	Loss 3.6120	Acc@1 79.396	Acc@5 96.456
 * Epoch 56, GPU 0, Acc@1 79.050, Acc@5 96.330, Time 27.08
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.123	Loss 1.3839	Acc@1 71.875	Acc@5 90.625
Test: [200/313]	GPU: 0	Time: 0.569	Loss 1.5636	Acc@1 64.956	Acc@5 89.708
 ** Acc@1 65.000, Acc@5 89.610
==> training...
Epoch: [57][0/782]	GPU 0	Time: 0.268	Loss 3.7497	Acc@1 76.562	Acc@5 93.750
Epoch: [57][200/782]	GPU 0	Time: 3.643	Loss 3.5207	Acc@1 80.348	Acc@5 96.859
Epoch: [57][400/782]	GPU 0	Time: 7.024	Loss 3.5671	Acc@1 79.582	Acc@5 96.668
Epoch: [57][600/782]	GPU 0	Time: 10.402	Loss 3.6136	Acc@1 79.157	Acc@5 96.443
 * Epoch 57, GPU 0, Acc@1 79.044, Acc@5 96.364, Time 26.69
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.122	Loss 1.6123	Acc@1 65.625	Acc@5 87.500
Test: [200/313]	GPU: 0	Time: 0.584	Loss 1.4790	Acc@1 65.532	Acc@5 89.303
 ** Acc@1 65.090, Acc@5 89.220
==> training...
Epoch: [58][0/782]	GPU 0	Time: 0.299	Loss 2.9498	Acc@1 82.812	Acc@5 100.000
Epoch: [58][200/782]	GPU 0	Time: 3.711	Loss 3.4793	Acc@1 80.325	Acc@5 96.727
Epoch: [58][400/782]	GPU 0	Time: 7.092	Loss 3.5189	Acc@1 79.894	Acc@5 96.637
Epoch: [58][600/782]	GPU 0	Time: 10.473	Loss 3.5667	Acc@1 79.399	Acc@5 96.563
 * Epoch 58, GPU 0, Acc@1 79.056, Acc@5 96.354, Time 26.78
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.124	Loss 1.5910	Acc@1 62.500	Acc@5 84.375
Test: [200/313]	GPU: 0	Time: 0.570	Loss 1.4048	Acc@1 66.200	Acc@5 89.988
 ** Acc@1 66.240, Acc@5 89.970
==> training...
Epoch: [59][0/782]	GPU 0	Time: 0.264	Loss 3.6186	Acc@1 76.562	Acc@5 96.875
Epoch: [59][200/782]	GPU 0	Time: 3.646	Loss 3.5546	Acc@1 79.664	Acc@5 96.618
Epoch: [59][400/782]	GPU 0	Time: 7.024	Loss 3.5592	Acc@1 79.769	Acc@5 96.575
Epoch: [59][600/782]	GPU 0	Time: 10.403	Loss 3.5879	Acc@1 79.378	Acc@5 96.519
 * Epoch 59, GPU 0, Acc@1 79.236, Acc@5 96.464, Time 26.71
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.126	Loss 1.3395	Acc@1 68.750	Acc@5 90.625
Test: [200/313]	GPU: 0	Time: 0.576	Loss 1.3607	Acc@1 66.511	Acc@5 89.879
 ** Acc@1 66.450, Acc@5 89.830
==> training...
Epoch: [60][0/782]	GPU 0	Time: 0.267	Loss 3.9362	Acc@1 79.688	Acc@5 98.438
Epoch: [60][200/782]	GPU 0	Time: 3.658	Loss 3.5665	Acc@1 79.874	Acc@5 96.688
Epoch: [60][400/782]	GPU 0	Time: 7.042	Loss 3.5801	Acc@1 79.516	Acc@5 96.637
