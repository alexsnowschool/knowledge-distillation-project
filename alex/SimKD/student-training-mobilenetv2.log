2024-05-08 11:11:24.854269: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-05-08 11:11:25.575061: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Use GPU: 0 for training
==> loading teacher model
==> done
6 0.5
Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ../data/cifar-100-python.tar.gz
  0%|          | 0/169001437 [00:00<?, ?it/s]  0%|          | 39936/169001437 [00:00<13:20, 211190.88it/s]  0%|          | 208896/169001437 [00:00<04:35, 612134.62it/s]  0%|          | 688128/169001437 [00:00<01:28, 1896944.57it/s]  1%|          | 1392640/169001437 [00:00<00:48, 3467724.63it/s]  2%|▏         | 2656256/169001437 [00:00<00:26, 6250770.33it/s]  3%|▎         | 4808704/169001437 [00:00<00:15, 10869441.30it/s]  4%|▍         | 6376448/169001437 [00:00<00:15, 10526731.05it/s]  6%|▌         | 9511936/169001437 [00:01<00:10, 15749998.03it/s]  7%|▋         | 12222464/169001437 [00:01<00:08, 18849154.97it/s]  9%|▉         | 15224832/169001437 [00:01<00:06, 21975375.81it/s] 11%|█         | 18215936/169001437 [00:01<00:06, 24239525.01it/s] 13%|█▎        | 21232640/169001437 [00:01<00:05, 25955986.70it/s] 14%|█▍        | 24231936/169001437 [00:01<00:05, 27130873.80it/s] 16%|█▌        | 27216896/169001437 [00:01<00:05, 27932487.05it/s] 18%|█▊        | 30176256/169001437 [00:01<00:04, 28423522.39it/s] 20%|█▉        | 33208320/169001437 [00:01<00:04, 28898340.31it/s] 21%|██▏       | 36248576/169001437 [00:01<00:04, 29274233.39it/s] 23%|██▎       | 39272448/169001437 [00:02<00:04, 29520259.01it/s] 25%|██▌       | 42296320/169001437 [00:02<00:04, 29675019.22it/s] 27%|██▋       | 45336576/169001437 [00:02<00:04, 29800766.25it/s] 29%|██▊       | 48376832/169001437 [00:02<00:04, 29902407.19it/s] 30%|███       | 51416064/169001437 [00:02<00:03, 29985310.80it/s] 32%|███▏      | 54432768/169001437 [00:02<00:03, 30029722.40it/s] 34%|███▍      | 57440256/169001437 [00:02<00:03, 30011073.82it/s] 36%|███▌      | 60480512/169001437 [00:02<00:03, 30039000.66it/s] 38%|███▊      | 63520768/169001437 [00:02<00:03, 30094604.69it/s] 39%|███▉      | 66531328/169001437 [00:02<00:03, 30070897.27it/s] 41%|████      | 69552128/169001437 [00:03<00:03, 30104287.27it/s] 43%|████▎     | 72563712/169001437 [00:03<00:03, 30083420.29it/s] 45%|████▍     | 75573248/169001437 [00:03<00:03, 30001321.74it/s] 46%|████▋     | 78573568/169001437 [00:03<00:03, 29993535.19it/s] 48%|████▊     | 81584128/169001437 [00:03<00:02, 29979257.73it/s] 50%|█████     | 84616192/169001437 [00:03<00:02, 30002188.93it/s] 52%|█████▏    | 87664640/169001437 [00:03<00:02, 30038837.11it/s] 54%|█████▎    | 90704896/169001437 [00:03<00:02, 30091036.00it/s] 55%|█████▌    | 93744128/169001437 [00:03<00:02, 30111459.30it/s] 57%|█████▋    | 96784384/169001437 [00:03<00:02, 30135668.75it/s] 59%|█████▉    | 99798016/169001437 [00:04<00:02, 30114612.30it/s] 61%|██████    | 102809600/169001437 [00:04<00:02, 30007464.20it/s] 63%|██████▎   | 105810944/169001437 [00:04<00:02, 29967894.01it/s] 64%|██████▍   | 108808192/169001437 [00:04<00:02, 29954856.33it/s] 66%|██████▌   | 111804416/169001437 [00:04<00:01, 29954723.70it/s] 68%|██████▊   | 114800640/169001437 [00:04<00:01, 29899389.80it/s] 70%|██████▉   | 117808128/169001437 [00:04<00:01, 29947565.63it/s] 71%|███████▏  | 120803328/169001437 [00:04<00:01, 29944862.74it/s] 73%|███████▎  | 123799552/169001437 [00:04<00:01, 29949733.36it/s] 75%|███████▌  | 126800896/169001437 [00:04<00:01, 29967267.97it/s] 77%|███████▋  | 129798144/169001437 [00:05<00:01, 29958326.98it/s] 79%|███████▊  | 132794368/169001437 [00:05<00:01, 29956639.74it/s] 80%|████████  | 135808000/169001437 [00:05<00:01, 30004210.98it/s] 82%|████████▏ | 138816512/169001437 [00:05<00:01, 30017405.54it/s] 84%|████████▍ | 141818880/169001437 [00:05<00:00, 30009192.47it/s] 86%|████████▌ | 144820224/169001437 [00:05<00:00, 29966973.11it/s] 87%|████████▋ | 147832832/169001437 [00:05<00:00, 30009861.94it/s] 89%|████████▉ | 150834176/169001437 [00:05<00:00, 29973575.93it/s] 91%|█████████ | 153840640/169001437 [00:05<00:00, 29991349.12it/s] 93%|█████████▎| 156848128/169001437 [00:05<00:00, 30009801.30it/s] 95%|█████████▍| 159849472/169001437 [00:06<00:00, 29997762.65it/s] 96%|█████████▋| 162849792/169001437 [00:06<00:00, 29995307.37it/s] 98%|█████████▊| 165850112/169001437 [00:06<00:00, 29987952.26it/s]100%|█████████▉| 168856576/169001437 [00:06<00:00, 30006616.17it/s]169001984it [00:06, 26543652.71it/s]                               
Extracting ../data/cifar-100-python.tar.gz to ../data/
Files already downloaded and verified
Test: [0/313]	GPU: 0	Time: 0.193	Loss 0.9604	Acc@1 81.250	Acc@5 87.500
Test: [200/313]	GPU: 0	Time: 1.105	Loss 1.0121	Acc@1 76.150	Acc@5 93.532
teacher accuracy:  76.3
==> training...
Epoch: [1][0/782]	GPU 0	Time: 0.397	Loss 1.6472	Acc@1 1.562	Acc@5 4.688
Epoch: [1][200/782]	GPU 0	Time: 5.710	Loss 1.3393	Acc@1 1.158	Acc@5 5.309
Epoch: [1][400/782]	GPU 0	Time: 10.971	Loss 1.3023	Acc@1 1.149	Acc@5 5.654
Epoch: [1][600/782]	GPU 0	Time: 16.172	Loss 1.2866	Acc@1 1.199	Acc@5 5.943
 * Epoch 1, GPU 0, Acc@1 1.294, Acc@5 6.404, Time 41.46
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.186	Loss 4.6790	Acc@1 3.125	Acc@5 12.500
Test: [200/313]	GPU: 0	Time: 1.752	Loss 4.5657	Acc@1 1.710	Acc@5 7.680
 ** Acc@1 1.840, Acc@5 8.330
saving the best model!
==> training...
Epoch: [2][0/782]	GPU 0	Time: 0.284	Loss 1.1701	Acc@1 4.688	Acc@5 7.812
Epoch: [2][200/782]	GPU 0	Time: 5.418	Loss 1.2303	Acc@1 2.021	Acc@5 8.839
Epoch: [2][400/782]	GPU 0	Time: 10.566	Loss 1.2298	Acc@1 2.116	Acc@5 9.601
Epoch: [2][600/782]	GPU 0	Time: 15.726	Loss 1.2268	Acc@1 2.316	Acc@5 10.381
 * Epoch 2, GPU 0, Acc@1 2.502, Acc@5 11.148, Time 40.65
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.142	Loss 4.3892	Acc@1 0.000	Acc@5 9.375
Test: [200/313]	GPU: 0	Time: 1.777	Loss 4.3443	Acc@1 3.156	Acc@5 15.003
 ** Acc@1 3.210, Acc@5 15.020
saving the best model!
==> training...
Epoch: [3][0/782]	GPU 0	Time: 0.291	Loss 1.1985	Acc@1 0.000	Acc@5 12.500
Epoch: [3][200/782]	GPU 0	Time: 5.650	Loss 1.1995	Acc@1 3.529	Acc@5 15.112
Epoch: [3][400/782]	GPU 0	Time: 11.016	Loss 1.2022	Acc@1 3.511	Acc@5 15.395
Epoch: [3][600/782]	GPU 0	Time: 16.269	Loss 1.1998	Acc@1 3.572	Acc@5 15.914
 * Epoch 3, GPU 0, Acc@1 3.680, Acc@5 16.438, Time 41.49
GPU 0 validating
Test: [0/313]	GPU: 0	Time: 0.155	Loss 4.2419	Acc@1 9.375	Acc@5 21.875
Test: [200/313]	GPU: 0	Time: 1.774	Loss 4.2015	Acc@1 4.820	Acc@5 19.325
 ** Acc@1 4.780, Acc@5 19.160
saving the best model!
==> training...
Epoch: [4][0/782]	GPU 0	Time: 0.286	Loss 1.2209	Acc@1 6.250	Acc@5 21.875
Epoch: [4][200/782]	GPU 0	Time: 5.569	Loss 1.1898	Acc@1 4.361	Acc@5 18.766
Epoch: [4][400/782]	GPU 0	Time: 10.857	Loss 1.1885	Acc@1 4.715	Acc@5 18.769
Epoch: [4][600/782]	GPU 0	Time: 16.164	Loss 1.1860	Acc@1 4.989	Acc@5 19.205
